{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Using K-Fold Cross-validation on the MNIST dataset\n",
    "Hands-on Machine Learning<br>\n",
    "20 December, 2018<br><br>\n",
    "\n",
    "\n",
    "## Step 1.  Load the MNIST dataset from Keras and prepare it for modelling\n",
    "\n",
    "Keras comes packaged with the MNIST dataset.  This has 60,000 images of handwritten digits, each of which is properly labeled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras import models, layers\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the image data into a (n, 784) array.\n",
    "# Then re-scale the data to a (0, 1) range.\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "# Conver the label data to categorical (on-hot encoding)\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.  Create a function to build network models \n",
    "<br>\n",
    "With K-fold cross-validation, we need to train and test each model configuration under multiple datasets.  We need a 'constructor' to compile identically-configured models.  Let's create a python function to do this.<br><br>\n",
    "When we want to adjust the hyper-parameters, we will need to make the adjustments to this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(512,\n",
    "                        activation='relu',\n",
    "                        input_shape=(28 * 28,)))\n",
    "    \n",
    "    model.add(layers.Dense(10,\n",
    "                        activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Train and validate, using K-fold cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New code\n",
    "k = 4\n",
    "foldSize = len(train_labels) // k\n",
    "\n",
    "validationScores=[] # create an empty list to hold the validation results at each fold.\n",
    "\n",
    "for fold in range(k):\n",
    "    # fold images/labels will be held out for VALIDATION\n",
    "    val_images = train_images[foldSize * fold: foldSize * (fold+1)]\n",
    "    val_labels = train_labels[foldSize * fold: foldSize * (fold+1)]\n",
    "    \n",
    "    # remaining images/labels will be used for TRAINING\n",
    "    partial_train_images = np.concatenate((train_images[:foldSize * fold],\n",
    "                                           train_images[foldSize * (fold+1):]))\n",
    "    \n",
    "    partial_train_labels = np.concatenate((train_labels[:foldSize * fold],\n",
    "                                           train_labels[foldSize * (fold+1):]))\n",
    "\n",
    "    # build, train and validate the model\n",
    "    model = build_model()\n",
    "    model.fit(partial_train_images, partial_train_labels,\n",
    "              epochs=2, \n",
    "              batch_size=128, \n",
    "              verbose=0)\n",
    "    \n",
    "    validationScore = model.evaluate(val_images, val_labels)\n",
    "    print(validationScore)\n",
    "    validationScores.append(validationScore)\n",
    "\n",
    "validationScores = np.mean(validationScores, axis=0)\n",
    "print()\n",
    "print('Results: Loss:',validationScores[0], 'Accuracy:', validationScores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Test the network, using previously unseen data\n",
    "<br>\n",
    "Once we are satisfied with our model design, it is time to test using unseen data.<br>\n",
    "Before we can do this, however, we need to build and train a new model.<br>\n",
    "The current model contains the weights from the final fold training.  We want to train this network design on the ENTIRE dataset.  This allows us to get maximum value from the entire training set.\n",
    "<br>\n",
    "\n",
    "### 4a.  Build and train a new copy of the network using the ENTIRE training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel = build_model()\n",
    "testModel.fit(train_images, train_labels,\n",
    "              epochs=2, # IMPORTANT: Use the value from your final model above!\n",
    "              batch_size=128,  # IMPORTANT: Use the value from your final model above!\n",
    "              verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b.  Evaluate the model using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loss, test_acc = testModel.evaluate(test_images, test_labels)\n",
    "print('test_loss', test_loss)\n",
    "print('test_acc', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
